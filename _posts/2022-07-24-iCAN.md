---
title: "iCAN: Instance-Centric Attention Network for Human-Object Interaction Detection"
date: "2022-07-24 00:00:00"
identifier: iCAN
category: HOI, Attention
hero: http://chengao.vision/iCAN/images/overview.png
link: http://chengao.vision/iCAN/
tags: ["Human-Object Interaction Detection", "Dataset"]
conference: BMVC
year: 2018
math: true
layout: post
---

# 概要

- 検出された人や物体のインスタンスごとに、タスクに関連する領域を強調するattentionマップを動的に生成する、HOI検出用ネットワークiCANを提案
- V-COCOで10%、HICO-DETで49%の性能向上
<!--more-->

# 新規性・差分

- HOI検出に画像レベルの分類タスクで使われるattentionモジュールを導入

# アイデア

![](http://chengao.vision/iCAN/images/overview.png)

- Faster R-CNNを用いて、すべての人と物体のインスタンスを検出
- Human/Object Stream
    - 人と物体のインスタンスの外観特徴をiCANモジュールに入れ、2層の全結合層に通して人スコア$s^a_o$と物体スコア$s^a_o$を取得
    - iCANモジュール
        - 図の処理を行うことで、類似度などを使ってattentionマップを作成し、外観特徴$x^h_{inst}$と文脈特徴$x^h_{context}$を取得して、連結したものを出力する  
        ![](http://chengao.vision/iCAN/images/iCAN.png)
            
- Pairwise stream
    - 人間の領域を1，それ以外を0とした2値画像と物体の領域を1，それ以外を0とした2値画像をCNNに入力して特徴抽出
        - 空間特徴を得ている
    - 空間特徴のみではうまくいかないため，人間の外観特徴$x^h_{inst}$を連結してから2層の全結合層に通してペアスコア$s^a_{sp}$を取得
- スコアの算出
    - Late fusion：人スコア$s^a_o$と物体スコア$s^a_o$を足して、ペアスコア$s^a_{sp}$を掛けることでスコアを算出
    - Early fusion：すべてのStreamのスコアを連結して、２つの全結合層に通してスコアを算出

# 結果

- V-COCO
    - ![VCOCO_quantitative.png](http://chengao.vision/iCAN/images/VCOCO_quantitative.png)
    - ![VCOCO.png](http://chengao.vision/iCAN/images/VCOCO.png)
    
- HICO-DET
    - ![HICO-DET_quantitative.png](http://chengao.vision/iCAN/images/HICO-DET_quantitative.png)
    - ![HICO.png](http://chengao.vision/iCAN/images/HICO.png)