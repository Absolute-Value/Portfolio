---
title: "Fully Convolutional Cross-Scale-Flows for Image-based Defect Detection"
date: 2021-10-28
identifier: CS-Flow
category: "Anomaly Detection"
hero: /assets/images/posts/CS-Flow/hero.png
link: https://arxiv.org/abs/2110.02855
tags: ["Anomaly Detection", "Flow"]
conference: WACV
year: 2022
math: true
layout: post
---

## 1. どんなもの?
<!-- 概要・貢献等 100-200字程度 -->
* 正規化フローと事前学習済みニューラルネットワークを用いた半教師あり学習
* 異なるスケールの画像を事前学習のネットワークに通した特徴マップを同時に学習することで、精度を向上
<!--more-->

## 2. 先行研究と比べてどこがすごい？
<!-- related worksとの差分 -->
* 他の手法は正規分布を仮定しているが、本手法では最尤推定によって真の分布を学習する
* 特徴マップに平均プーリングを適用したベクトルを処理すると重要な文脈情報や位置情報が失われてしまうが、本手法では完全な畳み込みアーキテクチャによって空間的な配置も保持

## 3. 技術や手法の"キモ"はどこ？
<!-- キモを箇条書きでまとめる -->
![](/assets/images/posts/CS-Flow/csflow-NF.png)

* 異なるスケールを同時に学習する正規化フローブロック。
    * これをいくつか重ねる
    * 実験ではサブネット内の畳み込みカーネルを3x3にしたものを3回、5x5にしたものを1回
* 詳細
    * 異なるスケールにした画像を事前学習済みネットワークに通した特徴量（実験ではEfficientNet-B5の36層目） をランダムに並べて半分に分ける
    * それぞれを $y^{(i)}\_{in,1}, y^{(i)}\_{in,2}$ とする
    * $y^{(i)}\_{in,2}$ と、 $y^{(i)}\_{in,1}$ を後述のサブネット $r\_1$ に通した $s_1(y\_{in,1}), t\_1(y\_{in,1})$ を用いて $y\_{out,2}$ は以下のようになる  
    $$ y_{out,2} = y_{in,2} \odot e^{\gamma_1 s_1(y_{in,1})} + \gamma_1 t_1(y_{in,1})$$
        * $\gamma_1$ は安定して初期化するためのスカラー係数
    * $y^{(i)}\_{in,1}$ と、 $y\_{out,2}$ を同様にサブネット $r\_2$ に通した $s_2(y\_{out,2}), t_2(y\_{out,2})$ を用いて $y\_{out,1}$ は以下のようになる  
    $$ y_{out,1} = y_{in,1} \odot e^{\gamma_2 s_2(y_{out,2})} + \gamma_2 t_2(y_{out,2})$$

![](/assets/images/posts/CS-Flow/csflow-block.png)
* サブネットの内部
    * 畳み込みをしている他、異なるスケールの特徴をアップサンプリングやストライド2での畳み込みにより、サイズを合わせて足し合わせることで、関連させている
    * 最後に半分にして前述の$s$と$t$に分けている

### 変数定義
<!--
学習・推論で使う変数をまとめる
* $x$: 入力画像
* $y$: 教師信号
-->
* $x$: 入力画像
* $y$: 入力画像$x$を事前学習ニューラルネットワークに通した特徴量
* $p_Y(y)$: $y$の尤度
* $L(y)$: 目的関数

### 学習
<!-- キモの中の学習に関する内容 -->
* 入力画像 $x$ を事前学習ニューラルネットワークに通した特徴量 $y=f_{fe}(x)$ の尤度 $p_Y(y)$を最大化したい
* $y$ を正規化フローに通した $z=f_{NF}(y)$から、尤度 $p_Y(y)$ を変数変換すると
$$ p_Y(y) = p_Z(z) \big|det \frac{\partial z}{\partial y} \big| $$
* $p_Y(y)$の最大化、すなわち負の対数尤度 $-\log p_Y(y)$ を最小化すれば良いので、目的関数は
$$ L(y) = -\log p_Y(y) 
= - \big( \log p_Z(z) + \log \big|det \frac{\partial z}{\partial y} \big| \big)\\
= \frac{|| z ||^2_2}{2} - \log \big|det \frac{\partial z}{\partial y} \big|$$

### 推論（異常度の算出）
<!-- キモの中の推論に関する内容 -->
* 尤度 $p_z(z)$ が閾値 $\theta$ より低いものを異常、高いものを正常とする  
<img src="/assets/images/posts/CS-Flow/csflow-ano.png" width="200px">

>## 4. どうやって有効だと検証した？
<!-- 実験の精度，結果画像など -->
* MVTec Detection
    * 4つのクラスでAUROC100%
![](/assets/images/posts/CS-Flow/csflow-detection.png)

* MVTec Localization
![](/assets/images/posts/CS-Flow/csflow-local.png)

* Magnetic Tile Defects (MTD) Datasets  
<img src="/assets/images/posts/CS-Flow/csflow-mtd.png" width="400px">

## 6. 関連文献
<!--
1. D. P. Kingma and J. Ba: “Adam: A method for stochastic optimization,”arXiv preprint arXiv:1412.6980,(2014).
2. P. Isola,J. Y. Zhu,T. Zhou,and A. A. Efros: “Image-to-image translation with conditional adversarial networks,” in Proceedings of the IEEE conference on computer vision and pattern recognition, (2017), 1125.
-->
1. Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
Density estimation using real nvp. ICLR 2017, 2016.
2. Marco Rudolph, Bastian Wandt, and Bodo Rosenhahn. Same
same but differnet: Semi-supervised defect detection with
normalizing flows. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages
1907–1916, 2021.