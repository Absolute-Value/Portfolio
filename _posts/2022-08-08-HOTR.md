---
title: "HOTR: End-to-End Human-Object Interaction Detection with Transformers"
date: "2022-08-08 00:00:00"
identifier: HOTR
category: HOI
hero: /assets/images/posts/HOTR/1.png
link: https://arxiv.org/abs/2104.13682
tags: ["Human-Object Interaction Detection", "Transformer"]
conference: CVPR
year: 2021
math: true
layout: post
---

# 概要

- transformerを初めてHuman-Object Interactionに利用した手法HOTRを提案
- オブジェクト検出とHOI検出の二段階の処理や、重複の削除などの後処理などが必要ない
- Self-Attentionにより文脈的関係を理解している
- V-COCOとHICO-DETデータセットにおいて最先端の性能かつ大幅に高速化
<!--more-->

# 新規性・差分

- 重複した予測の排除や閾値設定などの後処理が不要に
- これまでの検出器が5~9msかかる推論を1ms以下に高速化

# アイデア
![](/assets/images/posts/HOTR/1.png)

- アーキテクチャ
    - 1つの共有Encoderと2つの並列Decoder(Instance Decoder, Interaction Decoder)から成る
        - Encoderの共有は別々よりも有効だった
    - EncoderとInstance DecoderはDETRと同様にBackbone CNNで抽出した特徴をtransformerに通して、FFNで人と物体のバウンディングボックスとクラスを検出する
    - Interaction Decoderは、FFNでポインタを用いてInstance Decoderの人と物体を指し示し、HOIを予測する
    ![](/assets/images/posts/HOTR/2.png)
        
- 学習
    - マッチングコストを計算してマッチングしたペアについてハンガリーLossを計算する
    - DETRではNone Objectを設定できたが、HOIは複数の予測を同時に行うマルチラベル分類のため設定できない
        - そこで、対話性を予測するクラスを設定して、対話性の低いものは予測を抑制するようにした
    - Backbone、Encoder、Instance DecoderはMSCOCOで事前学習する

# 結果

- V-COCO
    - 高性能&高速化
        - ![](/assets/images/posts/HOTR/3.png)
        - ![](/assets/images/posts/HOTR/4.png)
- HICO-DET
    - ![](/assets/images/posts/HOTR/5.png)