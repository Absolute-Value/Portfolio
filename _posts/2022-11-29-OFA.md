---
title: "OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"
date: "2022-11-29 12:00:00"
identifier: QPIC
category: HOI
hero: /assets/images/posts/OFA/OFA.png
link: https://github.com/OFA-Sys/OFA
tags: ["Multimodal Pretraining", "Multitask Learning", "Unified Frameworks", "Zero-shot Learning", "Transformer"]
conference: ICML
year: 2022
math: true
layout: post
---

# 概要

- 包括的なタスクを行うことができる、タスクとモダリティを無視できるフレームワークであるOFA(One For All)を提案
    - Text2Image, Visual Grounding, VQA, Image Caption, Image Classification, language modeling
- 一般に公開されている2000万件の画像テキストペアのデータセットで事前学習
- 自然言語理解（RoBERTa、ELECTRA、DeBERTa）
自然言語生成（UniLM、Pegasus、 ProphetNet）
画像分類（MoCo-v3、BEiT、MAE）と同等のパフォーマンスを達成
- 未学習のタスクにも移行できる
<!--more-->

# 新規性・差分

- 下流タスクであるVQAや画像キャプションでの性能劣化が起きない
- 画像生成機能を持っている

# アイデア

- アーキテクチャ
    - ![](/assets/images/posts/OFA/OFA.png)
    - TransformerベースのEncoder Decoderフレームワーク
    - テキストと画像に対して絶対位置埋め込み
    - ハイパラ
        - ![](/assets/images/posts/OFA/HyperPram.png)
- 事前学習
    - ![](/assets/images/posts/OFA/PreTrain.png)
    

# 結果

- VQA and visual entailment
    - ![](/assets/images/posts/OFA/VQA.png)
    
- MSCOCO Image Captioning
    - ![](/assets/images/posts/OFA/ImageCaptioning.png)
    
- RefCOCO, RefCOCO+, RefCOCOg
    - ![](/assets/images/posts/OFA/RefCOCO.png)
    
- text-to-image generation task
    - ![](/assets/images/posts/OFA/Text2Image1.png)
    - ![](/assets/images/posts/OFA/Text2Image2.png)
    
- GLUE benchmark datasets
    - ![](/assets/images/posts/OFA/GLUE.png)
    
- Gigaword abstractive summarization
    - ![](/assets/images/posts/OFA/Gigaword.png)
    
- ImageNet-1K
    - ![](/assets/images/posts/OFA/ImageNet.png)
    
- unseen task grounded QA
    - ![](/assets/images/posts/OFA/UnseenTask.png)
    
- unseen domain VQA
    - ![](/assets/images/posts/OFA/UnseenDomain.png)