---
title: "Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders"
date: 2021-07-14
identifier: SSIM-AE
category: "Anomaly Detection"
hero: https://media.arxiv-vanity.com/render-output/5811705/SSIM_L2_COMPARISON.png
link: https://arxiv.org/abs/2107.05855
tags: ["Anomaly Detection", "Unsupervised Learning", "Anomaly Segmentation", "Autoencoder"]
conference: VISAPP
year: 2019
math: true
layout: post
---

## 1. どんなもの?
<!-- 概要・貢献等 100-200字程度 -->
通常の畳み込みオートエンコーダで使用されるピクセルLossは位置ズレに弱く、強度の値が一定の場合に弱い。  
そこで、輝度、コントラスト、構造情報を考慮した構造的類似性(SSIM)Lossを代わりに使用した。
<!--more-->

## 2. 先行研究と比べてどこがすごい？
<!-- related worksとの差分 -->
* エッジの整列にあまり影響されない
* 入力と再構成の間の顕著な違いを重要視する

## 3. 技術や手法の"キモ"はどこ？
<!-- キモを箇条書きでまとめる -->
* Pixel L2 Lossの代わりにSSIM Lossを使用

### 変数定義
<!--
学習・推論で使う変数をまとめる
* $x$:入力画像
* $\hat{x}$:再構成画像
-->
* $p$:画像パッチp
* $q$:画像パッチq
* $l$:輝度
* $c$:コントラスト
* $s$:構造情報
* $\alpha,\beta,\gamma,c_1,c_2$:パラメータ

### 学習
<!-- キモの中の学習に関する内容 
-->
* SSIM Loss 
    * $ SSIM(p,q) = \frac{(2 \mu_p \mu_q + C_1)(2 \sigma_{pq} + C_2)}{(\mu_p ^2 + \mu_q ^2 + C_1)(\sigma_p ^2 + \sigma_q ^2 + C_2)} $
        * 輝度の比較：
        $ l(p, q) = \frac{(2\mu_{p}\mu_{q} + C_{1})}{(\mu_{p}^2 + \mu_{q}^2 + C_{1})} $，
        コントラストの比較：
        $ c(p, q) = \frac{(2\sigma_{p}\sigma_{q} + C_{2})}{(\sigma_{p}^2 + \sigma_{q}^2 + C_{2})} $，
        構造の比較：
        $ s(p, q) = \frac{(2\sigma_{pq} + C_{3})}{(\sigma_{p}\sigma_{q} + C_{3})} $
        を
        $ SSIM(p, q) = [l(p, q)]^\alpha \times [c(p, q)]^\beta \times [s(p, q)]^\gamma $
        に代入して算出


* エンコーダの構造  

| Layer	| Output Size | Kernel | Stride | Padding |
|-|-|-|-|-|
| Input | 128×128×1 |
| Conv1 | 64×64×32 | 4×4 | 2 | 1 |
| Conv2	| 32×32×32 | 4×4 | 2 | 1 |
| Conv3	| 32×32×32 | 3×3 | 1 | 1 |
| Conv4	| 16×16×64 | 4×4 | 2 | 1 |
| Conv5	| 16×16×64 | 3×3 | 1 | 1 |
| Conv6	| 8×8×128 | 4×4 | 2 | 1 |
| Conv7	| 8×8×64 | 3×3 | 1 | 1 |
| Conv8	| 8×8×32 | 3×3 | 1 | 1 |
| Conv9	| 1×1×d	| 8×8 | 1 | 0 |

### 推論（異常度の算出）
<!-- キモの中の推論に関する内容 -->
* テスト画像と学習したオートエンコーダを用いて再構成した画像の残差マップを計算

## 4. どうやって有効だと検証した？
<!-- 実験の精度，結果画像など -->

* 織布テクスチャ
    * 再構成，残差マップ，検出結果のL2とSSIMの比較
    ![](https://media.arxiv-vanity.com/render-output/5811705/SSIM_L2_COMPARISON.png)
    * L2を使用したAE,VAE,FM-AEとSSIMを使用したAEのROC曲線
    ![](https://media.arxiv-vanity.com/render-output/5811705/x1.png)

>## 6. 関連文献
1. Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing, 13(4):600–612, 2004.