---
title: "Exploring Structure-aware Transformer over Interaction Proposals for Human-Object Interaction Detection"
date: "2023-02-21 11:00:00"
identifier: STIP
category: HOI
hero: /assets/images/posts/STIP/2.png
link: https://github.com/zyong812/STIP
tags: ["Human-Object Interaction Detection", "Transformer"]
conference: CVPR
year: 2022
math: true
layout: post
---

# 概要

- 新しいtransformerベースのHOI手法のStructure-aware Transformer over Interaction Proposals (STIP)を提案
- 「インタラクションのある人間と物体のペア提案」と「構造考慮型transformerで提案をHOIに変換」の2つのフェーズでHOIを予測
- 構造考慮型transformerはバニラtransformerに対し、全体的意味構造および各相互作用提案内のヒト／モノの局所的空間構造を追加的に符号化することでHOI予測を強化している
<!--more-->

# 新規性・差分

- ![](/assets/images/posts/STIP/1.png)
- 他のHOIに依存していることを考慮させた（例：「人間が（野球の）グローブをつけている」ゆえに、「（別の）人間がバットを持っている」）

# アイデア

- ![](/assets/images/posts/STIP/2.png)
- DETR
    - 人間と物体のインスタンスを検出
- Interaction Proposal Network (IPN)
    - すべての人間と物体のペアを構築
    - すべてのペアに対してインタラクションの確率を外観特徴と空間特徴と言語特徴をMLPに入れて予測
        - 外観特徴：DETRで得られる特徴
        - 空間特徴：$[dx, dy, dis, A_h, A_o, I, U]$
            - $dx$ : 人間と物体のx距離
            - $dy$ : 人間と物体のy距離
            - $dis$ : 人間と物体のユークリッド
            - $A_h$ : 人間の面積
            - $A_o$ : 物体の面積
            - $I$ : 人間と物体の面積の積集合
            - $U$ : 人間と物体の面積の和集合
        - 言語特徴：物体のラベル(OneHot)を200次元のベクトルに
    - インタラクションの確率が高い上位K組を提案として出力
        - $$ L_{proposal} = \frac{1}{\sum^N_{i=1}z_i} \sum^N_{i=1} FL(\hat{z}_i, z_i) $$

- インタラクション中心グラフ構築
    - インタラクション意味構造
        - ![](/assets/images/posts/STIP/4.png)
        - インタラクション提案をグラフノードとしてグラフを構築
        - 6つのクラス
            - disjunctive
                - 人間も物体もインスタンスを共有していない
            - same-human
            - same-object
                - 人間／物体のインスタンスのみ同じ
            - series-opposing
            - series
                - 人間／物体のインスタンスが物体／人間のインスタンスと同じ
            - same-pair
                - 人間と物体の両方のインスタンスが同じ
    - インタラクション空間構造
        - ![](/assets/images/posts/STIP/5.png)
        - 局所的な空間特徴を考慮させる
- Structure-aware transformer
    - Structure-aware Self-Attention
        - $$ e^{self}_{ij} = \frac{(W_q q_i)^T (W_k q_j + \psi (q_j, E_{dep}(d_{ij})))}{\sqrt{d_{key}}} $$
        - IPNのK組の提案に対してSelf-Attention
            - Keyに対してインタラクション意味構造の6つのクラスで意味依存性を付与する
        - $E_{dep}$は意味依存を符号化する2層MLP
    - Structure-aware Cross-attention
        - ![](/assets/images/posts/STIP/7.png)
        - $$ e^{cross}_{ij} = \frac{(W_{\hat{q}} \hat{q}_i)^T (W_{\hat{k}} x_j + pos_j+ \phi (x_j, E_{lay}(l_{ij})))}{\sqrt{d_{key}}} $$
        
        - K組の中間HOI特徴をQuery，画像特徴マップをKeyとValueとしCross-attention
            - Keyに対してインタラクション空間構造の5つのクラスを付与
- 最終出力
    - 2層MLPでインタラクションクラスを予測
        - Focal Loss likeな損失関数
            - $$ L_{cls} = \frac{1}{\sum^N_{i=1} \sum^C_{c=1}} \sum^N_{i=1} \sum^C_{c=1} FL (\hat{y}_{ic}, y_{ic}) $$
            
    - 全体の損失関数
        - $$ L_{STIP} = L_{proposal} + L_{cls} $$
        

# 結果

- V-COCO
    - ![](/assets/images/posts/STIP/11.png)
    
- HICO-DET
    - ![](/assets/images/posts/STIP/12.png)
    
- 提案のK組による精度比較
    - ![](/assets/images/posts/STIP/13.png)
    
- 構造考慮型transformerのレイヤー数によおる精度比較
    - ![](/assets/images/posts/STIP/14.png)