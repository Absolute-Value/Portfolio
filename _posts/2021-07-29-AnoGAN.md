---
title: "Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery"
date: 2021-07-29
identifier: AnoGAN
category: "Anomaly Detection"
hero: https://www.opst.co.jp/wp/wp-content/uploads/2021/09/report200708_01-1024x224.jpeg
link: https://arxiv.org/abs/1703.05921
tags: ["Anomaly Detection", "Unsupervised Learning", "GAN"]
conference: IPMI
year: 2017
math: true
layout: post
---

## 1. どんなもの?
<!-- 概要・貢献等 100-200字程度 -->
* GANを使用した教師なし異常検知
* 画像空間から潜在空間へのマッピングに基づく新しい異常スコアリングスキームを伴う
* 網膜の光コヒーレンス・トモグラフィー画像を用いた結果、網膜液や反射率の高い病巣を含む画像などの異常画像を正しく識別することができた
<!--more-->

## 2. 先行研究と比べてどこがすごい？
<!-- related worksとの差分 -->
* GANを異常や新規性の検出に初めて使用

## 3. 技術や手法の"キモ"はどこ？
<!-- キモを箇条書きでまとめる -->
![](https://www.opst.co.jp/wp/wp-content/uploads/2021/09/report200708_01-1024x224.jpeg)

### 変数定義
<!--
学習・推論で使う変数をまとめる
* $x$: 入力画像
* $y$: 教師信号
-->
* $x$: 入力画像
* $z$: 潜在空間
* $p_g$: 分布
* $G()$: Generator
* $D()$: Discriminator
* $f()$: 中間層の出力
* $R(x)$: 残差スコア
* $D(x)$: 識別スコア
* $A(x)$ 異常スコア


### 学習
<!-- キモの中の学習に関する内容 -->
* 通常のGANと同じ2プレイヤーのミニマックスゲーム
* 生成器Generatorは生成する能力を向上させる
* 識別機Discriminatorは実画像と生成された画像を識別する能力を向上させる  
$$ \min \_G \max \_D V(D, G) = \mathbb{E}_{\bf x \rm \sim p\_{data}(\bf x \rm)} [\log D(\bf x \rm)] + \mathbb{E}\_{\bf z \rm \sim p\_{\bf z \rm}(\bf z \rm)} [\log (1 - D(G(\bf z \rm)))] $$

### 推論（異常度の算出）
<!-- キモの中の推論に関する内容 -->
* Residual loss
    * $$ \mathcal{L}_R (\bf z\rm\_{\gamma}) = \sum |\bf x\rm - G(\bf z\rm\_{\gamma}) | $$
    * クエリ画像$x$と生成画像$G(z_\gamma)$の色覚的非類似性を測定
* discrimination loss
    * $$ \mathcal{L}_{D} (\bf z\rm\_{\gamma}) = \sum | f(\bf x\rm ) - f(G(z\rm\_{\gamma}))| $$
    * 識別機Dの中間層の出力$f()$を使用することによって、Dが学習した特徴表現の情報を考慮に入れる
    * 識別機Dを分類機ではなく特徴抽出器として使用
* これら二つのLossの加重和の損失関数
$$ \mathcal{L} (z\rm\_{\gamma}) = (1-\lambda) \cdot \mathcal{L}_R (\bf z\rm\_{\gamma}) + \lambda \cdot \mathcal{L}_{D} (\bf z\rm\_{\gamma}) $$を用いて  
$\gamma$回のバックプロパゲーションを繰り返すことにより最適な潜在変数$z\_\gamma$を得る。

* その潜在変数$z\_{\gamma}$を用いて、残差スコア$R(x) = \mathcal{L}\_R (\bf z\rm\_{\gamma})$と識別スコア$D(x) = \mathcal{L}\_D (z\rm\_{\gamma}) $と定義したとき、  
* クエリ画像$x$の異常スコア$A(x)$は
$$ A(\bf x\rm) = (1- \lambda) \cdot R(\bf x\rm) + \lambda \cdot D(\bf x\rm) $$
となる。

* 基準異常スコア
$$ \hat{A}(\bf x\rm) = (1- \lambda) \cdot R(\bf x\rm) + \lambda \cdot \hat{D}(\bf x\rm)\qquad(\because \hat{D}(x) = \mathcal{L_{\hat{D}}} (z\rm\_{\gamma}))$$
## 4. どうやって有効だと検証した？
<!-- 実験の精度，結果画像など -->
* 網膜の臨床高解像度SD-OCTボリューム  
* ![](https://cdn-ak.f.st-hatena.com/images/fotolife/a/aotamasaki/20180414/20180414211624.png)
    * 上から1行ごとに元画像、生成画像、異常個所、アノテーション  
    * 左から1ブロックごとに学習正常、テスト正常、テスト異常
* ![](https://www.researchgate.net/profile/Thomas-Schlegl-3/publication/318017139/figure/fig3/AS:473842939371520@1489984368215/Image-level-anomaly-detection-performance-and-suitability-evaluation-a-Model.png)
    * (a) 他モデルとの比較  
    * (b) 残差スコア(緑)、識別スコア(黒)、基準識別スコア(赤)に基づく異常検知精度  
    * (c) 残差スコアの分布  
    * (d) 判別スコアの分布

## 5. 議論はあるか？
<!-- 自分なりの考察や疑問-->
基準異常スコア
$$ \hat{A}(\bf x\rm) = (1- \lambda) \cdot R(\bf x\rm) + \lambda \cdot \hat{D}(\bf x\rm) $$  
異常判断スコア$$\hat{D}(x) = \mathcal{L_{\hat{D}}} (z\rm_{\gamma}) $$  
Yehら[https://arxiv.org/abs/1607.07539](https://arxiv.org/abs/1607.07539)とは

## 6. 関連文献
<!--
1. D. P. Kingma and J. Ba: “Adam: A method for stochastic optimization,”arXiv preprint arXiv:1412.6980,(2014).
2. P. Isola,J. Y. Zhu,T. Zhou,and A. A. Efros: “Image-to-image translation with conditional adversarial networks,” in Proceedings of the IEEE conference on computer vision and pattern recognition, (2017), 1125.
-->
1. Yeh, R., Chen, C., Lim, T.Y., Hasegawa-Johnson, M., Do, M.N.: Semantic image inpainting with perceptual and contextual losses. arXiv:1607.07539 (2016)