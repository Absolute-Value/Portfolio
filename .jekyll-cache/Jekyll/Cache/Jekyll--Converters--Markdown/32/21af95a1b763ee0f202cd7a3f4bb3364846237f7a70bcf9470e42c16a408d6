I"<h2 id="概要">概要</h2>

<ul>
  <li>VR環境のオブジェクトの指先での操作を目指す</li>
  <li>手の検出と指先の検出の２段階CNNを用いて、親指と人差し指のジェスチャーを検出</li>
  <li>ジェスチャーでVR環境内の物体をアフィン変換させる</li>
  <li>結果、既存手法より高い性能</li>
</ul>

<h2 id="新規性差分">新規性・差分</h2>

<h2 id="手法">手法</h2>

<p><img src="/assets/images/posts/Fingertips/1.png" alt="" /></p>
<ul>
  <li>指先検出システム
    <ul>
      <li>Hand Detection
        <ul>
          <li>物体検出モデル(YOLO)で手を検出</li>
        </ul>
      </li>
      <li>Cropped &amp; Resized
        <ul>
          <li>手の領域で切り取り、指定のサイズに</li>
        </ul>
      </li>
      <li>Feature Learning
        <ul>
          <li>分類モデル(VGG-16, InceptionV3, Xception, MobileNetV2)の特徴マップを平滑化し、NNで(親指のx,y座標, 人差し指のx,y座標)を出力するように学習</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="/assets/images/posts/Fingertips/1.png" alt="" /></p>
<ul>
  <li>Vuforiaを使用したインタラクションシステム
    <ul>
      <li>手の検出</li>
      <li>指の検出</li>
      <li>指の距離、角度、重心を計算</li>
      <li>計算値からVRオブジェクトをアフィン変換（拡大縮小、回転、平行移動）</li>
    </ul>
  </li>
</ul>

<h2 id="結果">結果</h2>

<p><img src="https://user-images.githubusercontent.com/37298971/78501859-96a26b00-777f-11ea-9f33-977ea8feda09.gif" alt="" /></p>
:ET