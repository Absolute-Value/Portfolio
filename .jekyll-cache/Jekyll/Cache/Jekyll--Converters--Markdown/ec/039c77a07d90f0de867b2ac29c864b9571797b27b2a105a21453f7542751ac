I"<h2 id="1-どんなもの">1. どんなもの?</h2>
<!-- 概要・貢献等 100-200字程度 -->
<p>通常の畳み込みオートエンコーダで使用されるピクセルLossは位置ズレに弱く、強度の値が一定の場合に弱い。<br />
そこで、輝度、コントラスト、構造情報を考慮した構造的類似性(SSIM)Lossを代わりに使用した。
<!--more--></p>

<h2 id="2-先行研究と比べてどこがすごい">2. 先行研究と比べてどこがすごい？</h2>
<!-- related worksとの差分 -->
<ul>
  <li>エッジの整列にあまり影響されない</li>
  <li>入力と再構成の間の顕著な違いを重要視する</li>
</ul>

<h2 id="3-技術や手法のキモはどこ">3. 技術や手法の”キモ”はどこ？</h2>
<!-- キモを箇条書きでまとめる -->
<ul>
  <li>Pixel L2 Lossの代わりにSSIM Lossを使用</li>
</ul>

<h3 id="変数定義">変数定義</h3>
<!--
学習・推論で使う変数をまとめる
* $x$:入力画像
* $\hat{x}$:再構成画像
-->
<ul>
  <li>$p$:画像パッチp</li>
  <li>$q$:画像パッチq</li>
  <li>$l$:輝度</li>
  <li>$c$:コントラスト</li>
  <li>$s$:構造情報</li>
  <li>$\alpha,\beta,\gamma,c_1,c_2$:パラメータ</li>
</ul>

<h3 id="学習">学習</h3>
<!-- キモの中の学習に関する内容 
-->
<ul>
  <li>SSIM Loss
    <ul>
      <li>$ SSIM(p,q) = \frac{(2 \mu_p \mu_q + C_1)(2 \sigma_{pq} + C_2)}{(\mu_p ^2 + \mu_q ^2 + C_1)(\sigma_p ^2 + \sigma_q ^2 + C_2)} $
        <ul>
          <li>輝度の比較：
  $ l(p, q) = \frac{(2\mu_{p}\mu_{q} + C_{1})}{(\mu_{p}^2 + \mu_{q}^2 + C_{1})} $，
  コントラストの比較：
  $ c(p, q) = \frac{(2\sigma_{p}\sigma_{q} + C_{2})}{(\sigma_{p}^2 + \sigma_{q}^2 + C_{2})} $，
  構造の比較：
  $ s(p, q) = \frac{(2\sigma_{pq} + C_{3})}{(\sigma_{p}\sigma_{q} + C_{3})} $
  を
  $ SSIM(p, q) = [l(p, q)]^\alpha \times [c(p, q)]^\beta \times [s(p, q)]^\gamma $
  に代入して算出</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>エンコーダの構造</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Layer</th>
      <th>Output Size</th>
      <th>Kernel</th>
      <th>Stride</th>
      <th>Padding</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Input</td>
      <td>128×128×1</td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Conv1</td>
      <td>64×64×32</td>
      <td>4×4</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Conv2</td>
      <td>32×32×32</td>
      <td>4×4</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Conv3</td>
      <td>32×32×32</td>
      <td>3×3</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Conv4</td>
      <td>16×16×64</td>
      <td>4×4</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Conv5</td>
      <td>16×16×64</td>
      <td>3×3</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Conv6</td>
      <td>8×8×128</td>
      <td>4×4</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Conv7</td>
      <td>8×8×64</td>
      <td>3×3</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Conv8</td>
      <td>8×8×32</td>
      <td>3×3</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Conv9</td>
      <td>1×1×d</td>
      <td>8×8</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<h3 id="推論異常度の算出">推論（異常度の算出）</h3>
<!-- キモの中の推論に関する内容 -->
<ul>
  <li>テスト画像と学習したオートエンコーダを用いて再構成した画像の残差マップを計算</li>
</ul>

<h2 id="4-どうやって有効だと検証した">4. どうやって有効だと検証した？</h2>
<!-- 実験の精度，結果画像など -->

<ul>
  <li>織布テクスチャ
    <ul>
      <li>再構成，残差マップ，検出結果のL2とSSIMの比較
  <img src="https://media.arxiv-vanity.com/render-output/5811705/SSIM_L2_COMPARISON.png" alt="" /></li>
      <li>L2を使用したAE,VAE,FM-AEとSSIMを使用したAEのROC曲線
  <img src="https://media.arxiv-vanity.com/render-output/5811705/x1.png" alt="" /></li>
    </ul>
  </li>
</ul>

<blockquote>
  <h2 id="6-関連文献">6. 関連文献</h2>
  <ol>
    <li>Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing, 13(4):600–612, 2004.</li>
  </ol>
</blockquote>
:ET